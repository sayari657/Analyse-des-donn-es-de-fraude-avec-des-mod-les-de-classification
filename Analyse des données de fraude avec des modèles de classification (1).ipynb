{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6793623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03be2ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score, precision_score, recall_score,f1_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c6aaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51c952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\MSI\\\\Downloads\\\\archive (2)\\\\exam.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c062ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b341fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3185c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d49bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.isnull().values.any():\n",
    "    print('There are some missing values in this dataset\\n')\n",
    "    df.dropna(inplace=True)\n",
    "    print('Shape : ', data.shape) \n",
    "else:\n",
    "    print('GREAT, There is no missing values in th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0461c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, orient='h') # horizontal\n",
    "plt.title('Outliers')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c7297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d49994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.title('type vs counts')\n",
    "sns.countplot(data=df,x='type')\n",
    "plt.xlabel('Type')\n",
    "plt.ylabel('Counts')\n",
    "plt.grid(axis='y', alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].replace({'CASH_OUT':0, 'PAYMENT':1, 'CASH_IN':2, 'TRANSFER':3, 'DEBIT':4}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ab060",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ecb316",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dfab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"isFraud\" feature\n",
    "df['isFraud'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e4a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['isFraud'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Target_counts = df['isFraud'].value_counts()\n",
    "\n",
    "# Plot\n",
    "\n",
    "sns.barplot(x=Target_counts.index, y=Target_counts.values, palette='flare')\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Counts of Target\\n NOT Fraud = 0 || IS Fraud = 1)')\n",
    "plt.xticks()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbc6a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['nameOrig', 'nameDest'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd5f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a497d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding correlation\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba46de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of Correlation\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(df.corr(), \n",
    "            annot=True, \n",
    "            linewidths=0.9, \n",
    "            fmt=\".1f\", vmin=-1, vmax=1,\n",
    "            cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e0cc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['newbalanceOrig', 'oldbalanceDest'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca5827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac809e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9da0bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X Data\n",
    "x = df.drop(['isFraud'], axis=1)\n",
    "print('X shape is : ' , x.shape)\n",
    "print()\n",
    "\n",
    "# y Data\n",
    "y = df['isFraud']\n",
    "print('Y shape is : ' , y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5917abfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "# Splitted Data\n",
    "print('X_train shape is ' , X_train.shape)\n",
    "print('X_test shape is ' , X_test.shape)\n",
    "print('y_train shape is ' , y_train.shape)\n",
    "print('y_test shape is ' , y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eaee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization (Z-Score Normalization) \n",
    "# StandardScaler for Data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform the training and testing data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312b2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_LR = LogisticRegression()\n",
    "Model_LR.fit(X_train_scaled, y_train)\n",
    "y_pred_LR = Model_LR.predict(X_test_scaled)\n",
    "\n",
    "# Quick evaluation\n",
    "Train_Accuracy = Model_LR.score(X_train_scaled, y_train)\n",
    "Test_Accuracy = Model_LR.score(X_test_scaled, y_test)\n",
    "print(f'Training accuracy: {Train_Accuracy*100:.2f} %')\n",
    "print(f'Testing accuracy: {Test_Accuracy*100:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f26d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = confusion_matrix(y_true=y_test, y_pred=y_pred_LR)\n",
    "ConfusionMatrixDisplay(CM, display_labels=df['isFraud'].unique()).plot()\n",
    "plt.title('Confusion Matrix Without Normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5e3a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_LR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577ef7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "Accuracy_LR = accuracy_score(y_test, y_pred_LR)\n",
    "\n",
    "\n",
    "# Precision = TP / (TP + FP)\n",
    "Precision_LR = precision_score(y_test, y_pred_LR)\n",
    "\n",
    "\n",
    "# Recall = TP / (TP + FN)\n",
    "Recall_LR = recall_score(y_test, y_pred_LR)\n",
    "\n",
    "\n",
    "# F1 Score = 2 × ((Precision * Recall) / (Precision + Recall))\n",
    "F1_Score_LR = f1_score(y_test, y_pred_LR)\n",
    "print(f'F1 Score : {F1_Score_LR * 100 : .2f} %\\n')\n",
    "\n",
    "\n",
    "ROC_AUC_LR = roc_auc_score(y_test, y_pred_LR)\n",
    "\n",
    "\n",
    "print(f'Accuracy Score : {Accuracy_LR * 100 : .2f} %\\n')\n",
    "print(f'Precision Score : {Precision_LR * 100 : .2f} %\\n')\n",
    "print(f'Recall Score : {Recall_LR * 100 : .2f} %\\n')\n",
    "print(f'AUC_ROC : {ROC_AUC_LR * 100 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf9bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scores = [Accuracy_LR, Precision_LR, Recall_LR, F1_Score_LR, ROC_AUC_LR]\n",
    "Score_Names = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC-ROC']\n",
    "\n",
    "# Plot\n",
    "plt.pie(Scores, labels=Score_Names, \n",
    "        autopct='%1.2f%%', \n",
    "        startangle=140, \n",
    "        labeldistance=1.15,\n",
    "       wedgeprops = { 'linewidth' : .5, 'edgecolor' : 'white' })\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4857d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_DT = DecisionTreeClassifier()\n",
    "Model_DT.fit(X_train_scaled, y_train)\n",
    "y_pred_DT = Model_DT.predict(X_test_scaled)\n",
    "\n",
    "# Quick evaluation\n",
    "Train_Accuracy = Model_DT.score(X_train_scaled, y_train)\n",
    "Test_Accuracy = Model_DT.score(X_test_scaled, y_test)\n",
    "print(f'Training accuracy: {Train_Accuracy*100:.2f} %')\n",
    "print(f'Testing accuracy: {Test_Accuracy*100:.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c239784",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CM = confusion_matrix(y_true=y_test, y_pred=y_pred_DT)\n",
    "ConfusionMatrixDisplay(CM, display_labels=df['isFraud'].unique()).plot()\n",
    "plt.title('Confusion Matrix Without Normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ba520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_DT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1625ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "Accuracy_DT = accuracy_score(y_test, y_pred_DT)\n",
    "\n",
    "\n",
    "# Precision = TP / (TP + FP)\n",
    "Precision_DT = precision_score(y_test, y_pred_DT)\n",
    "\n",
    "\n",
    "# Recall = TP / (TP + FN)\n",
    "Recall_DT = recall_score(y_test, y_pred_DT)\n",
    "\n",
    "\n",
    "# F1 Score = 2 × ((Precision * Recall) / (Precision + Recall))\n",
    "F1_Score_DT = f1_score(y_test, y_pred_DT)\n",
    "\n",
    "\n",
    "ROC_AUC_DT = roc_auc_score(y_test, y_pred_DT)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f'Accuracy Score : {Accuracy_DT * 100 : .2f} %\\n')\n",
    "print(f'Precision Score : {Precision_DT * 100 : .2f} %\\n')\n",
    "print(f'Recall Score : {Recall_DT * 100 : .2f} %\\n')\n",
    "print(f'F1 Score : {F1_Score_DT * 100 : .2f} %\\n')\n",
    "print(f'AUC_ROC : {ROC_AUC_DT * 100 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0559b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Score_Names = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC-ROC']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.pie(Scores, labels=Score_Names, autopct='%1.2f%%', startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a464995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_NB = GaussianNB()\n",
    "Model_NB.fit(X_train_scaled, y_train)\n",
    "y_pred_NB = Model_NB.predict(X_test_scaled)\n",
    "\n",
    "# Quick evaluation\n",
    "Train_Accuracy = Model_NB.score(X_train_scaled, y_train)\n",
    "Test_Accuracy = Model_NB.score(X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9924d4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CM = confusion_matrix(y_true=y_test, y_pred=y_pred_NB)\n",
    "ConfusionMatrixDisplay(CM, display_labels=df['isFraud'].unique()).plot()\n",
    "plt.title('Confusion Matrix Without Normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300ddc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_NB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d136d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "Accuracy_NB = accuracy_score(y_test, y_pred_NB)\n",
    "\n",
    "\n",
    "# Precision = TP / (TP + FP)\n",
    "Precision_NB = precision_score(y_test, y_pred_NB)\n",
    "\n",
    "\n",
    "# Recall = TP / (TP + FN)\n",
    "Recall_NB = recall_score(y_test, y_pred_NB)\n",
    "\n",
    "\n",
    "# F1 Score = 2 × ((Precision * Recall) / (Precision + Recall))\n",
    "F1_Score_NB = f1_score(y_test, y_pred_NB)\n",
    "\n",
    "\n",
    "ROC_AUC_NB = roc_auc_score(y_test, y_pred_NB)\n",
    "\n",
    "\n",
    "print(f'Accuracy Score : {Accuracy_NB * 100 : .2f} %\\n')\n",
    "print(f'Precision Score : {Precision_NB * 100 : .2f} %\\n')\n",
    "print(f'Recall Score : {Recall_NB * 100 : .2f} %\\n')\n",
    "print(f'F1 Score : {F1_Score_NB * 100 : .2f} %\\n')\n",
    "print(f'AUC_ROC : {ROC_AUC_NB * 100 : ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scores = [Accuracy_NB, Precision_NB, Recall_NB, F1_Score_NB, ROC_AUC_NB]\n",
    "Score_Names = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC-ROC']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.pie(Scores, labels=Score_Names, autopct='%1.2f%%', startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d093ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame({'Classification Model': ['Logistic Regression','Decision Tree', 'Naive Bayes'],\n",
    "                           'Accuracy Rate': [(Accuracy_LR*100).round(2), (Accuracy_DT*100).round(2), (Accuracy_NB*100).round(2)]})\n",
    "\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1615e6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54448f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
